{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b6cc13",
   "metadata": {},
   "source": [
    "# **Introduction**\n",
    "\n",
    "This notebook is for testing stable baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb9701",
   "metadata": {},
   "source": [
    "# **Import Packages**\n",
    "\n",
    "Import the necessary packages for this implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdefd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import these:\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45153f6f",
   "metadata": {},
   "source": [
    "# **Define Hyperparameters**\n",
    "\n",
    "This section defines the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment:\n",
    "env_name = \"Reacher-v5\"\n",
    "env = Monitor(gym.make(env_name), \"./monitor_logs\")\n",
    "\n",
    "# hyperparameters:\n",
    "policy = \"MlpPolicy\"\n",
    "gamma = 0.99\n",
    "learning_rate = 3e-4\n",
    "buffer_size = int(1e6)\n",
    "learning_starts = 10000\n",
    "train_freq = 1\n",
    "batch_size = 64\n",
    "tau = 0.005\n",
    "ent_coef = 'auto'\n",
    "target_update_interval = 1\n",
    "gradient_steps = 1\n",
    "target_entropy = 'auto'\n",
    "action_noise = None\n",
    "random_exploration = 0.0\n",
    "verbose = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e46f2e",
   "metadata": {},
   "source": [
    "# **Create and Use Model**\n",
    "\n",
    "This section first creates the model using the defined hyperparameters, and then learns a policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC(policy = policy,\n",
    "            env = env, \n",
    "            gamma = gamma,\n",
    "            learning_rate = learning_rate,\n",
    "            buffer_size = buffer_size,\n",
    "            learning_starts = learning_starts,\n",
    "            train_freq = train_freq,\n",
    "            batch_size = batch_size,\n",
    "            tau = tau, \n",
    "            ent_coef = ent_coef,\n",
    "            target_update_interval = target_update_interval,\n",
    "            gradient_steps = gradient_steps,\n",
    "            target_entropy = target_entropy,\n",
    "            action_noise = action_noise,\n",
    "            verbose = verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9044c733",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b398c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in trange(100, ncols = 100, colour = \"#33FF00\", desc = \"training progress\"):\n",
    "    # train for 1000 steps:\n",
    "    model.learn(total_timesteps = 1000, reset_num_timesteps = False)\n",
    "\n",
    "    # get the data-frame:\n",
    "    df = pd.read_csv(\"monitor_logs.monitor.csv\", skiprows = 1)\n",
    "\n",
    "    # return to user:\n",
    "    if not df.empty:\n",
    "        last_reward = df[\"r\"].iloc[-1]\n",
    "        mean_last_10 = df[\"r\"].tail(10).mean()\n",
    "        print(f\"current episodic reward: {last_reward:.2f} | \"\n",
    "                f\"mean of last 10: {mean_last_10:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68586d",
   "metadata": {},
   "source": [
    "# **Visualization**\n",
    "\n",
    "This section visualizes the learned policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a13cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render settings:\n",
    "width = 1280\n",
    "height = 1280\n",
    "\n",
    "match env_name:\n",
    "    case \"InvertedPendulum-v5\":\n",
    "        default_camera_config = {\"azimuth\" : 90.0, \"elevation\" : 0.0, \"distance\" : 3.5, \"lookat\" : [0.0, 0.0, 0.25]}\n",
    "        env = gym.make(env_name,\n",
    "                    healthy_reward = 10.0,\n",
    "                    render_mode = \"human\", \n",
    "                    width = width,\n",
    "                    height = height,\n",
    "                    default_camera_config = default_camera_config)\n",
    "\n",
    "    case \"InvertedDoublePendulum-v5\":\n",
    "        default_camera_config = {\"azimuth\" : 90.0, \"elevation\" : 0.0, \"distance\" : 3.5, \"lookat\" : [0.0, 0.0, 0.25]}\n",
    "        env = gym.make(env_name,\n",
    "                    healthy_reward = 10.0,\n",
    "                    render_mode = \"human\", \n",
    "                    width = width,\n",
    "                    height = height,\n",
    "                    default_camera_config = default_camera_config)\n",
    "    case \"Reacher-v5\":\n",
    "        default_camera_config = {\"azimuth\" : 90.0, \"elevation\" : -90.0, \"distance\" : 1.5, \"lookat\" : [0.0, 0.0, 0.25]}\n",
    "        env = gym.make(env_name,\n",
    "                        render_mode = \"human\",\n",
    "                        reward_dist_weight = 1.0,\n",
    "                        width = width, \n",
    "                        height = height,\n",
    "                        default_camera_config = default_camera_config, \n",
    "                        max_episode_steps = 50)  \n",
    "\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic = True)\n",
    "    obs, reward, term, trunc, _ = env.step(action)\n",
    "    done = term or trunc\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
