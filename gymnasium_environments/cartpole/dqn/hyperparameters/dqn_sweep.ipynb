{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cbaedc1",
   "metadata": {},
   "source": [
    "# **Introduction**\n",
    "\n",
    "This notebook is for testing hyperparameter optimization using `Optuna`, which is a hyperparameter optimization framework used to automate hyperparameter searching. The idea is to take the DQN implementation developed for `Cartpole`, both the base and swingup versions, and perform a hyperparameter search to optimize their performance using `Optuna`. The hyperparameters that will be optimized are:\n",
    "\n",
    "* The learning rate: α\n",
    "* The discount rate: γ\n",
    "* The epsilon decay rate: $ε_{d}$\n",
    "* The final epsilon value: $ε_{f}$\n",
    "* The replay buffer size: $n_{buff}$\n",
    "* The batch size: $n_{batch}$\n",
    "* The target update frequency: $f_{target}$\n",
    "* The training frequency: $f_{train}$\n",
    "* The training length: $n_{train}$\n",
    "* The warmup length: $n_{warm}$\n",
    "* The number of neurons per layer: $n_{neurons}$\n",
    "* The number of layers: $n_{layers}$\n",
    "\n",
    "With the goal being to maximize the average return per episode over a set number of trials. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
